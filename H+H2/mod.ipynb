{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fc837800650>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model=tf.keras.models.load_model(\"model0.keras\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# import rpmdrate.lm as lm\n",
    "workingDirectory = \"300/32\"\n",
    "PMF_filename=os.path.join(workingDirectory, 'potential_of_mean_force.dat')\n",
    "PMF_tem=os.path.join(workingDirectory, 'PMF')\n",
    "with open (PMF_filename,\"r\")as f:\n",
    "    PMF_str=f.readlines()[12:-1]\n",
    "    with open(PMF_tem,\"w\")as fw:\n",
    "        fw.writelines(PMF_str)\n",
    "PMF_data=np.loadtxt(PMF_tem)\n",
    "os.remove(PMF_tem)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "PMF_data=PMF_data[:]\n",
    "#data:需要进行分割的数据集\n",
    "#random_state:设置随机种子，保证每次运行生成相同的随机数\n",
    "#test_size:将数据分割成训练集的比例\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "# PMF_data = scaler.fit_transform(PMF_data)\n",
    "model0 = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(16, activation='tanh',input_shape=(1,)),\n",
    "                tf.keras.layers.Dense(8, activation='tanh'),\n",
    "                # tf.keras.layers.Dense(10),\n",
    "                tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "model0.load_weights(\"model_check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "Using matplotlib backend: QtAgg\n"
     ]
    }
   ],
   "source": [
    "plt.plot(np.linspace(-1.5,1.5,10000),model0.predict(np.linspace(-1.5,1.5,10000)))\n",
    "plt.scatter(PMF_data[:,0],PMF_data[:,1],c=\"r\")\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot((((np.tanh((np.tanh(np.linspace(-1,1,100000).reshape(-1,1)@model.weights[0])+model.weights[1])@model.weights[2])+model.weights[3])@model.weights[4])+model.weights[5]))\n",
    "x=np.linspace(-1,1,100000).reshape(-1,1)\n",
    "in0=np.tanh(x@model.weights[0]+model.weights[1])\n",
    "in1=np.tanh(in0@model.weights[2]+model.weights[3])\n",
    "out=(in1@model.weights[4]+model.weights[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    np.savetxt(f\"weights_{i}\",np.array(model0.weights[i*2]).T.reshape(-1,1))\n",
    "    np.savetxt(f\"biases_{i}\",model0.weights[i*2+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'Sequential'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mmodel0\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'Sequential'"
     ]
    }
   ],
   "source": [
    "a=np.loadtxt(\"weights_1\")\n",
    "a[0]-model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=np.empty([16,8])\n",
    "with open(\"weights_1\",\"r\")as f:\n",
    "    a=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[float(i) for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for i in range(8):\n",
    "    for j in range(16):\n",
    "        w1[j,i]=a[n]\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([14.328398], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.constant([0.6])\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y=model0(x)\n",
    "dy=tape.gradient(y,x)\n",
    "dy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
